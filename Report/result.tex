\section{Result \& Discussion}
\justify
In the perceptron model, we see the naive precision ((true positive + true negative) / total data points) for the best performance is only around 0.50, i.e. not much better than random guess.

The first challenge we face is, what should our vocabulary be, if we were to project the vocabulary into a vector space ourselves. One way is to use all words in the training set, but since embedding requires huge amounts of data to be accurate, this can't work well. Another way could be, to retrieve all questions on Quora, and use the words in all those questions as the vocabulary. The problem of this method is, we would actually be peeking into the testing set, since inevitably the testing set would be from Quora. A third method would be, to use some third party source to construct the vocabulary and the corresponding word vectors.

We believe the third method is the best, and hence we use the Google News vectors (https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM) as our embedding.

The second challenge is that, due to the computational complexity and hardware dependencies of the model, specifically the requirements of the Theano package, we were not able to replicate the training of the LSTM model ourselves before the deadline of the project. Instead, we used a pre-trained model to do the prediction, namely the Siamese LSTM (https://github.com/aditya1503/Siamese-LSTM) model trained based on the sentences involving compositional knowledge dataset (Marelli et al 2014) as a proxy. We feed the question pairs into the Siamese model, and it would produce the similarity measure between them. We then run a simple test to find the threshold beyond which we should predict duplicate. Based on the test, setting the threshold at 0.19 can give us a best f1 score of 0.59, and setting the threshold at 0.34 we can have a best "naive" prediction precision of 66%.

If we were to train the LSTM RNN ourselves, we would feed it with our labelled data, in the form of (question 1, question2, label) where label is a boolean indicating whether the two questions are duplicate or not, and the test data would be in the form of (question 1, question2). This way, since the model would be directly predicting whether the questions are duplicate or not instead of their semantic similarity, the model performance would be much better.

