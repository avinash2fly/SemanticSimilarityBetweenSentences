Model Choice

Based on our analysis, this problem is in essense the measurement of the similarity between two sentences. Based on our analysis, since questions are short in length, the bag of words plus naive Bayes model, which is based on pure statistics of word frequencies, would not work well. Even so, we tried a perceptron model on the data. What we observed was that the parameters did not converge even after 2,000 data points, and if we plot the data, we see it's not linearly separable. If we feed the data to the incompletely trained perceptron, we see the naive precision ((true positive + true negative) / total data points) is around 0.50, i.e. not much better than random guess. We then decided that we need a non-linear model to tackle this problem.

After some research, we decided that the LSTM recursive neural network is the best model for measuring the similarity between two sentences. After obtaining the similarity between the sentences, we can learn a threshold for the similarity measure, and predict the pairs of questions whose similarity measures are above this threshold to be duplicates, and those whose similarity measures are below this threshold to be non-dupicates.

Data Preprocessing

One way to translate words into features that could be accepted by machines is to use one hot encoding, with which each word would be translated into a boolean vector whose length equals the size of the vocabulary. Dimension reduction methods need to be applied on the resulted boolean vector as well. A better way to represent words could be to project each word into a real valued vector space. This method is invented by Google and has proven success in the literature. Hence, we adopt this method to preprocess our data. After preprocessing, each question would be represented by a list of vectors, each of which representing the original word.

Challenges and Discussion

The first challenge we face is, what should our vocabulary be, if we were to project the vocabulary into a vector space ourselves. One way is to use all words in the training set, but since embedding requires huge amounts of data to be accurate, this can't work well. Another way could be, to retrieve all questions on Quora, and use the words in all those questions as the vocabulary. The problem of this method is, we would actually be peeking into the testing set, since inevitably the testing set would be from Quora. A third method would be, to use some third party source to construct the vocabulary and the corresponding word vectors.

We believe the third method is the best, and hence we use the Google News vectors (https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM) as our embedding.

The second challenge is that, due to the computational complexity and hardware dependencies of the model, specifically the requirements of the theano package, we were not able to replicate the training of the LSTM model ourselves before the deadline of the project. Instead, we used a pre-trained model to do the prediction, namely the Siaseme LSTM (https://github.com/aditya1503/Siamese-LSTM) model trained based on the sentences involving compositional knowledge dataset (Marelli et al 2014) as a proxy. We feed the question pairs into the Siaseme model, and it would produce the similarity measure between them. We then run a simple test to find the threshold beyond which we should predict duplicate. Based on the test, setting the threshold at 0.19 can give us a best f1 score of 0.59, and setting the threshold at 0.34 we can have a best "naive" prediction precision of 66%.

If we were to train the LSTM RNN ourselves, we would feed it with our labelled data, in the form of (question 1, question2, label) where label is a boolean indicating whether the two questions are duplicate or not, and the test data would be in the form of (question 1, question2). This way, since the model would be directly predicting whether the questions are duplicate or not instead of their semantic similarity, the model performance would be much better.
